{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97af3ce5",
   "metadata": {},
   "source": [
    "# Clustering of roads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed780c93",
   "metadata": {},
   "source": [
    "This notebook contains the code for the clustering of the roads in Milan using different features, such as K_road (source and dest), betweenness and VOC. It also contains the code of the clustering analysis of the different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumolib\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import ConvexHull\n",
    "from result_utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e03f405",
   "metadata": {},
   "source": [
    "#### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf411694",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Milano_big'\n",
    "fold_prefix = 'baseline'\n",
    "p_kroad = 75\n",
    "p_bc = 75\n",
    "\n",
    "# road network path\n",
    "road_network_path = \"../data/road_net/\"+city+\"/\"+city+\"_road_network.net.xml\"\n",
    "\n",
    "# road-edge map\n",
    "path_road_edge_mapping = '../data/road_net/'+city+'/'+city+'_road_edge_map.csv'\n",
    "\n",
    "# experiment results\n",
    "folder_experiments = '../data/simulations/'+city+'/'+fold_prefix+'/sumo_out/'\n",
    "\n",
    "# output paths\n",
    "path_results = \"../data/simulations/\"+city+\"/\"+fold_prefix+\"/results/\"\n",
    "path_plots = \"../data/simulations/\"+city+\"/\"+fold_prefix+\"/plots/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "231ecc00",
   "metadata": {},
   "source": [
    "## 1. K_road aggregation and betweenness centrality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae689663",
   "metadata": {},
   "source": [
    "Load k_road origin and destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_results+'kroad_O_'+fold_prefix+'.json', 'r') as f:\n",
    "    k_road_o = json.load(f)\n",
    "with open(path_results+'kroad_D_'+fold_prefix+'.json', 'r') as f:\n",
    "    k_road_d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec757922",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_edge_map = pd.read_csv(path_road_edge_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f43265",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_road_o_df = pd.DataFrame(columns=['edge_id', 'k_road_o'])\n",
    "k_road_o_df['edge_id'] = k_road_o.keys()\n",
    "k_road_o_df['k_road_o'] = k_road_o.values()\n",
    "\n",
    "k_road_d_df = pd.DataFrame(columns=['edge_id', 'k_road_d'])\n",
    "k_road_d_df['edge_id'] = k_road_d.keys()\n",
    "k_road_d_df['k_road_d'] = k_road_d.values()\n",
    "\n",
    "k_road_od_df = pd.merge(k_road_o_df, k_road_d_df, on='edge_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e08a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_road computed aggregating by road and with weighted average on length\n",
    "\n",
    "k_road_df = pd.merge(k_road_od_df, road_edge_map, on='edge_id', how='left')\n",
    "weighted_avg = lambda x: np.average(x, weights=k_road_df.loc[x.index, \"edge_len\"])\n",
    "k_road_df = k_road_df.groupby(by=['road']).agg({'k_road_o': weighted_avg, 'k_road_d': weighted_avg}).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ccb19ff",
   "metadata": {},
   "source": [
    "Load betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47355ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_results+'bc_igraph_'+fold_prefix+'.json', 'r') as f:\n",
    "    edge_bc_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize bc\n",
    "val = list(edge_bc_map.values())\n",
    "max_val = np.max(val)\n",
    "min_val = np.min(val)\n",
    "for k,v in edge_bc_map.items():\n",
    "    edge_bc_map[k] = (v - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc01c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_edge_df = pd.DataFrame()\n",
    "bc_edge_df['edge_id'] = edge_bc_map.keys()\n",
    "bc_edge_df['bc'] = edge_bc_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df = pd.merge(bc_edge_df, road_edge_map, on='edge_id', how='left')\n",
    "weighted_avg = lambda x: np.average(x, weights=bc_df.loc[x.index, \"edge_len\"])\n",
    "bc_df = bc_df.groupby(by=['road']).agg({'bc': weighted_avg}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.merge(bc_df, k_road_df, on='road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "del bc_df, bc_edge_df, edge_bc_map, val\n",
    "del k_road_d, k_road_d_df, k_road_o, k_road_o_df, k_road_od_df, k_road_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67fae1fd",
   "metadata": {},
   "source": [
    "## 2. VOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca94a6",
   "metadata": {},
   "source": [
    "Compute the Volume-Over-Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94226383",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_exps = create_dict_exps(folder_experiments, 'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70456a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all experiments results and compute the mean and the std of the 'total_of' column.\n",
    "# It returns a dictionary with keys = roadnames and list [mean, std].\n",
    "\n",
    "def create_dict_total_per_edge(dict_exps, folder_experiments, main_experiment_name, total_of):\n",
    "    dict_total = {}\n",
    "    for exp_id, exp_folder_name in dict_exps[main_experiment_name].items():\n",
    "        exp_df = pd.read_csv(folder_experiments+exp_folder_name+\"/edge_measures.csv\")\n",
    "        \n",
    "        for ind, row in exp_df.iterrows():\n",
    "            if row['edge_id'] in dict_total:\n",
    "                dict_total[row['edge_id']].append(row[total_of])\n",
    "            else:\n",
    "                dict_total[row['edge_id']] = [row[total_of]]\n",
    "    \n",
    "    list_df = []\n",
    "    for edge, total in dict_total.items():\n",
    "        list_df.append([edge, np.array(total).mean(), np.array(total).std()])\n",
    "    df = pd.DataFrame(list_df, columns=['edge_id', 'mean', 'std'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716040a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_volume = create_dict_total_per_edge(dict_exps, folder_experiments, 'baseline', 'total_v_edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_capacity(sumo_edges):\n",
    "\n",
    "    conversion_factor = 2.2369362912\n",
    "    q = 0.5\n",
    "\n",
    "    edge_capacity = {}\n",
    "\n",
    "    for edge in sumo_edges:\n",
    "\n",
    "        speed_m_s = edge.getSpeed()\n",
    "        sl = speed_m_s*conversion_factor\n",
    "\n",
    "        num_lanes = edge.getLaneNumber()\n",
    "\n",
    "        # when the speed limit of a road segment sl≤45, it is defined as an arterial road\n",
    "        if sl <= 45:\n",
    "            capacity = 1900*num_lanes*q\n",
    "        # when the speed limit of a road segment 45<sl<60, it is defined as a highway\n",
    "        elif 45<sl<60:\n",
    "            capacity = (1000+20*sl)*num_lanes\n",
    "        # when the speed limit of a road segment sl ≥60, it is defined as a freeway\n",
    "        elif sl>=60:\n",
    "            capacity = (1700+10*sl)*num_lanes\n",
    "\n",
    "        edge_capacity[edge.getID()] = capacity\n",
    "        \n",
    "    return edge_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_network = sumolib.net.readNet(road_network_path, withInternal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_capacity = compute_edge_capacity(road_network.getEdges())\n",
    "df_edge_capacity = pd.DataFrame(df_edge_capacity.items(), columns=['edge_id', 'capacity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voc = pd.merge(df_edge_volume, df_edge_capacity, on='edge_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4eaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voc['voc'] = df_voc['mean']/df_voc['capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_edge_map = pd.read_csv(path_road_edge_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voc = pd.merge(df_voc, road_edge_map, on='edge_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde061",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg = lambda x: np.average(x, weights=df_voc.loc[x.index, \"edge_len\"])\n",
    "df_voc = df_voc.groupby(by=['road']).agg({'voc': weighted_avg}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.merge(corr_df, df_voc, on='road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3275ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(7,9))\n",
    "fig.suptitle('Milano_big k_road - VOC correlation', fontweight='bold', y=0.93)\n",
    "\n",
    "axs[0].scatter(corr_df['k_road_o'], corr_df['voc'], s=1)\n",
    "axs[0].set_title('k_road origin', fontsize=10)\n",
    "axs[0].set_xticks(np.arange(0,48,2))\n",
    "#axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel('k_road')\n",
    "axs[0].set_ylabel('VOC')\n",
    "\n",
    "axs[1].scatter(corr_df['k_road_d'], corr_df['voc'], s=1)\n",
    "axs[1].set_title('k_road destination', fontsize=10)\n",
    "axs[1].set_xticks(np.arange(0,30,2))\n",
    "#axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel('k_road')\n",
    "axs[1].set_ylabel('VOC')\n",
    "\n",
    "plt.savefig(path_plots+'k_road_voc_corr.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K_road_o - VOC Pearson corr: '+str(scipy.stats.pearsonr(corr_df['k_road_o'], corr_df['voc']).statistic))\n",
    "print('K_road_d - VOC Pearson corr: '+str(scipy.stats.pearsonr(corr_df['k_road_d'], corr_df['voc']).statistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c778d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "ax.scatter(corr_df['bc'], corr_df['voc'], s=1)\n",
    "ax.set_title('Betweenness centrality - VOC correlation', fontsize=10)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('bc')\n",
    "ax.set_ylabel('VOC')\n",
    "\n",
    "plt.savefig(path_plots+'bc_voc_corr.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Betweenness - VOC Pearson corr: '+str(scipy.stats.pearsonr(corr_df['bc'], corr_df['voc']).statistic))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f306844",
   "metadata": {},
   "source": [
    "## 3. Correlation with CO2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all experiments results and compute the mean and the std of the 'total_of' column.\n",
    "# It returns a dictionary with keys = roadnames and list [mean, std].\n",
    "\n",
    "def create_dict_total_per_road(dict_exps, folder_experiments, main_experiment_name, total_of):\n",
    "    dict_total = {}\n",
    "    for exp_id, exp_folder_name in dict_exps[main_experiment_name].items():\n",
    "        exp_df = pd.read_csv(folder_experiments+exp_folder_name+\"/road_measures.csv\")\n",
    "        \n",
    "        for ind, row in exp_df.iterrows():\n",
    "            if row['road'] in dict_total:\n",
    "                dict_total[row['road']].append(row[total_of])\n",
    "            else:\n",
    "                dict_total[row['road']] = [row[total_of]]\n",
    "    \n",
    "    list_df = []\n",
    "    for road, total in dict_total.items():\n",
    "        list_df.append([road, np.array(total).mean(), np.array(total).std()])\n",
    "    df = pd.DataFrame(list_df, columns=['road', 'mean', 'std'])\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7052745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2_road = create_dict_total_per_road(dict_exps, folder_experiments, 'baseline', 'total_co2')\n",
    "df_co2_len = pd.merge(road_edge_map.groupby('road')['edge_len'].sum(), df_co2_road, on=['road'])\n",
    "df_co2_len['co2'] = df_co2_len['mean']/df_co2_len['edge_len']\n",
    "df_co2_len['co2_std'] = df_co2_len['std']/df_co2_len['edge_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d58d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.merge(corr_df, df_co2_len[['road', 'co2', 'co2_std']], on=['road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792bbdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "ax.scatter(corr_df['voc'], corr_df['co2'], s=1)\n",
    "ax.set_title('VOC - CO2 correlation', fontsize=10)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('VOC')\n",
    "ax.set_ylabel('CO2')\n",
    "\n",
    "plt.savefig(path_plots+'co2_voc_corr.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VOC - CO2 Spearman corr: '+str(scipy.stats.spearmanr(corr_df['voc'], corr_df['co2']).correlation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73c47f9a",
   "metadata": {},
   "source": [
    "## 4. Add type of road"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cfb7d",
   "metadata": {},
   "source": [
    "Add the type of the road obtained from a split using the K_road and the betweenness centrality. It used for the comparison with the clustering technqiues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495edd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_type_road(df, k_road_percentile, bc_percentile, origin=True):\n",
    "    types = []\n",
    "    if origin:\n",
    "        k_road = 'k_road_o'\n",
    "    else:\n",
    "        k_road = 'k_road_d'\n",
    "    k_road_high = np.percentile(corr_df[k_road], p_kroad)\n",
    "    bc_high = np.percentile(corr_df['bc'], p_bc)\n",
    "\n",
    "    for ids, row in corr_df.iterrows():\n",
    "        if row[k_road] >= k_road_high and row['bc'] >= bc_high:\n",
    "            types.append('connector')\n",
    "        elif row[k_road] < k_road_high and row['bc'] >= bc_high:\n",
    "            types.append('peripheral')\n",
    "        elif row[k_road] >= k_road_high and row['bc'] < bc_high:\n",
    "            types.append('attractor')\n",
    "        else:\n",
    "            types.append('local')\n",
    "\n",
    "    return types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba323d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df['y_o'] = split_type_road(corr_df, p_kroad, p_bc, origin=True)\n",
    "corr_df['y_d'] = split_type_road(corr_df, p_kroad, p_bc, origin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a97db",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'connector':'red', 'attractor':'orange', 'peripheral':'green', 'local':'grey'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labels = pd.read_csv(path_results+'road_clust_map.csv')\n",
    "corr_df = pd.merge(corr_df, clust_labels, on=['road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7508719",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_clust = {'HF': '#de8f05', 'HE': '#029e73', 'LF':'#d55e00', 'LE':'#949494'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c0fe35a",
   "metadata": {},
   "source": [
    "## 5. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242c4e6",
   "metadata": {},
   "source": [
    "Compute the clustering using the different features and the different clustering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a45fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(5,6))\n",
    "fig.suptitle('Milano_big k_road - betwenness correlation', fontweight='bold', y=0.93)\n",
    "\n",
    "#axs[0].scatter(corr_df['k_road_o'], corr_df['bc'], c=corr_df['y_o'].map(colors), s=1)\n",
    "axs[0].scatter(corr_df['k_road_o'], corr_df['bc'], c=corr_df['clust_label'].map(colors_clust), s=1)\n",
    "axs[0].set_xticks(np.arange(0,48,2))\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel('k_road_o')\n",
    "axs[0].set_ylabel('bc')\n",
    "\n",
    "#axs[1].scatter(corr_df['k_road_d'], corr_df['bc'], c=corr_df['y_d'].map(colors), s=1)\n",
    "axs[1].scatter(corr_df['k_road_d'], corr_df['bc'], c=corr_df['clust_label'].map(colors_clust), s=1)\n",
    "axs[1].set_xticks(np.arange(0,30,2))\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel('k_road_d')\n",
    "axs[1].set_ylabel('bc')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7320dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, accuracy_score, jaccard_score, f1_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, fowlkes_mallows_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0960e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corr_df[['k_road_o', 'k_road_d', 'bc', 'voc']].values\n",
    "y_o = corr_df['y_o'].values\n",
    "y_d = corr_df['y_d'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaler       inertia (4)     silhouette (4)      calinski (4)        behavior\n",
    "## unscaled     30000 (40k)     0.47 (0.50)         8000 (9k)           6 clusters, vertically divided by k_road\n",
    "## minmax       55 (60)         0.44 (0.45)         4800 (5100)         5 clusters, vertically divided by k_road\n",
    "## standard     8000 (10k)      0.52 (0.55)         3700 (3700)         5 clusters, vertically divided by k_road, but low bc separated\n",
    "## robust       40000 (60k)     0.66 (0.67)         5100 (4700)         6 clusters, horizontally divided by betweenness for low k_road"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c58f6f46",
   "metadata": {},
   "source": [
    "### 5.1 K-means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dee0d792",
   "metadata": {},
   "source": [
    "#### 5.1.1 Grid search k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each clustering repeated 20 times, best number of clusters selected with elbow method\n",
    "## K-means params       time    inertia     silhouette      calinski\n",
    "## k-means++ - lloyd    21m     [4,5]       [4,5]           [3,4,5]\n",
    "## k-means++ - elkan    22m     [4,5]       [4,5,6]         [3,4,5]\n",
    "## random - lloyd       27m     [4,5]       [4,5]           [3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.arange(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ceb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_score = {} #inertia (sum of squared distances) --> the lower the better --> elbow method\n",
    "sil_score = {} #silhouette --> 1 better, -1 worse --> elbow method\n",
    "ch_score = {} #calinski_harabasz index --> the higher the better --> elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)\n",
    "for i in clusters:\n",
    "    ssd_tmp = []\n",
    "    sil_tmp = []\n",
    "    ch_tmp = []\n",
    "    for j in range(0, 20):\n",
    "        clf = KMeans(n_clusters=i, init='k-means++', n_init=5, algorithm='lloyd').fit(X_scaled)\n",
    "        ssd_tmp.append(clf.inertia_)\n",
    "        sil_tmp.append(silhouette_score(X_scaled, clf.labels_))\n",
    "        ch_tmp.append(calinski_harabasz_score(X_scaled, clf.labels_))\n",
    "\n",
    "    ssd_score[i] = np.array(ssd_tmp).mean()\n",
    "    sil_score[i] = np.array(sil_tmp).mean()\n",
    "    ch_score[i] = np.array(ch_tmp).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ssd_score.keys(), ssd_score.values(), '-o', ms=3)\n",
    "elbow = KneeLocator(list(ssd_score.keys()), list(ssd_score.values()), curve='convex', direction='decreasing').knee\n",
    "plt.axvline(elbow, c='tab:red', ls='--')\n",
    "plt.xticks(clusters)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "#plt.savefig(path_plots+'kmeans_inertia.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f52870",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sil_score.keys(), sil_score.values(), '-o', ms=3)\n",
    "elbow = KneeLocator(list(ssd_score.keys()), list(ssd_score.values()), curve='convex', direction='decreasing').knee\n",
    "plt.axvline(elbow, c='tab:red', ls='--')\n",
    "plt.xticks(clusters)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette')\n",
    "#plt.savefig(path_plots+'kmeans_silhouette.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ch_score.keys(), ch_score.values(), '-o', ms=3)\n",
    "elbow = KneeLocator(list(ssd_score.keys()), list(ssd_score.values()), curve='convex', direction='decreasing').knee\n",
    "plt.axvline(elbow, c='tab:red', ls='--')\n",
    "plt.xticks(clusters)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Calinski-Harabasz')\n",
    "#plt.savefig(path_plots+'kmeans_calinski.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dab149e",
   "metadata": {},
   "source": [
    "#### 5.1.2 K-means with 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98330de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans(n_clusters=4, init='k-means++', n_init=200, algorithm='lloyd').fit(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884668c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)\n",
    "print('Inertia: ', clf.inertia_)\n",
    "print('Silhouette score: ', silhouette_score(X_scaled, clf.labels_))\n",
    "print('Calinski-Harabasz score: ', calinski_harabasz_score(X_scaled, clf.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARS: random labeling --> 0, perfect labeling --> 1\n",
    "# FMS: similarity between two clustering, 0 --> no similarity, 1 --> perfect similarity\n",
    "\n",
    "print('Adjusted Rand Score origin: ', adjusted_rand_score(y_o, clf.labels_))\n",
    "print('Fowlked Mallows Score origin: ', fowlkes_mallows_score(y_o, clf.labels_))\n",
    "print('Adjusted Rand Score destination: ', adjusted_rand_score(y_d, clf.labels_))\n",
    "print('Fowlked Mallows Score destination: ', fowlkes_mallows_score(y_d, clf.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9526dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df['clust_label'] = clf.labels_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "325f3e8f",
   "metadata": {},
   "source": [
    "#### 5.1.3 Assign old categories to new clusters (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(clf.labels_))\n",
    "types = ['connector', 'attractor', 'peripheral', 'local']\n",
    "all_comb = []\n",
    "for k in itertools.permutations(labels):\n",
    "    d = {}\n",
    "    for p in zip(k, types):\n",
    "        d[p[0]] = p[1]\n",
    "    all_comb.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605fe964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin\n",
    "best_comb = {}\n",
    "for c in all_comb:\n",
    "    key = ('-').join([str(i) for sub in c.items() for i in sub])\n",
    "    best_comb[key] = {}\n",
    "    y_clust = pd.Series(clf.labels_).map(c).values\n",
    "    best_comb[key]['accuracy'] = accuracy_score(y_o, y_clust)\n",
    "    best_comb[key]['jaccard'] = jaccard_score(y_o, y_clust, average='weighted')\n",
    "    best_comb[key]['f1'] = f1_score(y_o, y_clust, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd909e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy:', max([(k,v['accuracy']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best jaccard:', max([(k,v['jaccard']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best f1:', max([(k,v['f1']) for k,v in best_comb.items()], key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88672483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination\n",
    "best_comb = {}\n",
    "for c in all_comb:\n",
    "    key = ('-').join([str(i) for sub in c.items() for i in sub])\n",
    "    best_comb[key] = {}\n",
    "    y_clust = pd.Series(clf.labels_).map(c).values\n",
    "    best_comb[key]['accuracy'] = accuracy_score(y_d, y_clust)\n",
    "    best_comb[key]['jaccard'] = jaccard_score(y_d, y_clust, average='weighted')\n",
    "    best_comb[key]['f1'] = f1_score(y_d, y_clust, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e344e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy:', max([(k,v['accuracy']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best jaccard:', max([(k,v['jaccard']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best f1:', max([(k,v['f1']) for k,v in best_comb.items()], key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da999c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_clust = {0:'green', 1:'red', 2:'grey', 3:'orange'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fcf3f3e",
   "metadata": {},
   "source": [
    "#### 5.1.4 Clustering interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc735e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(10,10))\n",
    "fig.suptitle('Milano_big correlation after clustering', fontweight='bold', y=0.93)\n",
    "\n",
    "centers = scaler.inverse_transform(clf.cluster_centers_)\n",
    "colors_clust = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red'}\n",
    "#c = clf.labels_\n",
    "c = pd.Series(clf.labels_).map(colors_clust)\n",
    "\n",
    "axs[0,0].scatter(X[:, 0], X[:, 2], s=1, c=c)\n",
    "axs[0,0].scatter(centers[:, 0], centers[:, 2], c='black', s=5)\n",
    "axs[0,0].set_yscale('log')\n",
    "axs[0,0].set_xlabel('k_road_o')\n",
    "axs[0,0].set_ylabel('bc')\n",
    "\n",
    "axs[0,1].scatter(X[:, 1], X[:, 2], s=1, c=c)\n",
    "axs[0,1].scatter(centers[:, 1], centers[:, 2], c='black', s=5)\n",
    "axs[0,1].set_yscale('log')\n",
    "axs[0,1].set_xlabel('k_road_d')\n",
    "axs[0,1].set_ylabel('bc')\n",
    "\n",
    "axs[1,0].scatter(X[:, 0], X[:, 3], s=1, c=c)\n",
    "axs[1,0].scatter(centers[:, 0], centers[:, 3], c='black', s=5)\n",
    "axs[1,0].set_xlabel('k_road_o')\n",
    "axs[1,0].set_ylabel('VOC')\n",
    "\n",
    "axs[1,1].scatter(X[:, 1], X[:, 3], s=1, c=c)\n",
    "axs[1,1].scatter(centers[:, 1], centers[:, 3], c='black', s=5)\n",
    "axs[1,1].set_xlabel('k_road_d')\n",
    "axs[1,1].set_ylabel('VOC')\n",
    "\n",
    "axs[2,0].scatter(X[:, 2], X[:, 3], s=1, c=c)\n",
    "axs[2,0].scatter(centers[:, 2], centers[:, 3], c='black', s=5)\n",
    "axs[2,0].set_yscale('log')\n",
    "axs[2,0].set_xscale('log')\n",
    "axs[2,0].set_xlabel('bc')\n",
    "axs[2,0].set_ylabel('VOC')\n",
    "\n",
    "fig.delaxes(axs[2,1])\n",
    "\n",
    "#plt.savefig(path_plots+'k_road_bc_corr.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05649d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_network = sumolib.net.readNet(road_network_path, withInternal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43194208",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_speed_map = {}\n",
    "for edge in road_network.getEdges():\n",
    "    if len(edge.getOutgoing()) > 1:\n",
    "        edge_speed_map[edge.getID()] = [edge.getSpeed(), 1]\n",
    "    else:\n",
    "        edge_speed_map[edge.getID()] = [edge.getSpeed(), 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_speed = pd.DataFrame(edge_speed_map.items(), columns=['edge_id', 'speed'])\n",
    "df_edge_speed['intersection'] = df_edge_speed['speed'].apply(lambda x: x[1])\n",
    "df_edge_speed['speed'] = df_edge_speed['speed'].apply(lambda x: x[0]*3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_edge_map = pd.read_csv(path_road_edge_mapping)\n",
    "road_edge_map = pd.merge(df_edge_speed, road_edge_map, on='edge_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_edge_map = road_edge_map.groupby('road').agg({'edge_len':'sum',\n",
    "                                                   'intersection':'sum',\n",
    "                                                   'speed': lambda x: pd.Series.mode(x).iloc[0]}).reset_index().rename(columns={'edge_len':'road_len'})\n",
    "corr_df = pd.merge(corr_df, road_edge_map, on='road', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99915bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8674ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# road types: high full (HF), high empty (HE), low full (LF), low empty (LE)\n",
    "clust_map = {0:'HE', 1:'LE', 2:'HF', 3:'LF'}\n",
    "road_clust = corr_df[['road', 'clust_label']]\n",
    "road_clust['clust_label'] = road_clust['clust_label'].apply(lambda x: clust_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a309d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#road_clust.to_csv(path_results+'road_clust_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d109ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = pd.DataFrame(scaler.inverse_transform(clf.cluster_centers_), columns=['k_road_o', 'k_road_d', 'bc', 'voc']).reset_index().rename(columns={'index':'clust_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['bc', 'k_road_o', 'k_road_d', 'voc', 'co2', 'road_len', 'intersection', 'speed']\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(18,8))\n",
    "\n",
    "for i in zip(col, itertools.product(range(2), range(4))):\n",
    "    sns.boxplot(x=corr_df['clust_label'], y=corr_df[i[0]], notch=True, showcaps=False, flierprops={\"marker\": \"x\"}, ax=axs[i[1]])\n",
    "\n",
    "axs[0,0].set_yscale('log') #bc\n",
    "axs[0,3].set_yscale('log') #voc\n",
    "axs[1,0].set_yscale('log') #co2\n",
    "axs[1,1].set_yscale('log') #road_len\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6189dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['bc', 'k_road_o', 'k_road_d', 'voc']\n",
    "pp = sns.pairplot(corr_df, vars=col, kind='scatter', diag_kind='hist', hue='clust_label', palette='tab10', \n",
    "                  plot_kws={'alpha':0.7, 's':7})\n",
    "\n",
    "for ax in pp.axes.flat:\n",
    "    if ax.get_xlabel() in ['bc', 'voc']:\n",
    "        ax.set(xscale='log')\n",
    "    if ax.get_ylabel() in ['bc']:\n",
    "        ax.set(yscale='log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13268ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['bc', 'k_road_o', 'k_road_d', 'voc', 'co2', 'road_len', 'intersection', 'speed']\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(18,8))\n",
    "\n",
    "for i in zip(col, itertools.product(range(2), range(4))):\n",
    "    sns.histplot(data=corr_df, x=i[0], hue='clust_label', element='step', ax=axs[i[1]], palette='tab10')\n",
    "\n",
    "axs[0,0].set_xscale('log') #bc\n",
    "axs[0,3].set_xscale('log') #voc\n",
    "axs[1,0].set_xscale('log') #co2\n",
    "axs[1,1].set_xscale('log') #road_len\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aeb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(4,4))\n",
    "\n",
    "sns.scatterplot(data=corr_df, x='k_road_o', y='bc', hue='clust_label', palette='tab10', alpha = 0.6, s=10)\n",
    "# plot centroids\n",
    "sns.scatterplot(data=centroids, x='k_road_o', y='bc', marker='^', hue='clust_label', palette='tab10', s=70, legend=False)\n",
    "\n",
    "# plot lines\n",
    "tmp = pd.merge(corr_df, centroids, on='clust_label', how='left')\n",
    "colors_clust = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red'}\n",
    "for idx, val in tmp.iterrows():\n",
    "    x = [val['k_road_o_x'], val['k_road_o_y']]\n",
    "    y = [val['bc_x'], val['bc_y']]\n",
    "    plt.plot(x, y, alpha=0.2, c=colors_clust[val['clust_label']])\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['bc', 'k_road_o', 'k_road_d', 'voc']\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15,8))\n",
    "\n",
    "for i in zip(itertools.combinations(col,2), itertools.product(range(2), range(3))):\n",
    "    sns.scatterplot(data=corr_df, x=i[0][0], y=i[0][1], hue='clust_label', palette='tab10', alpha = 0.7, s=7, ax=axs[i[1]])\n",
    "    # plot centroids\n",
    "    sns.scatterplot(data=centroids, x=i[0][0], y=i[0][1], marker='^', hue='clust_label', palette='tab10', s=70, legend=False, ax=axs[i[1]])\n",
    "\n",
    "    # draw enclosure\n",
    "    for j in corr_df['clust_label'].unique():\n",
    "        points = corr_df[corr_df['clust_label'] == j][[i[0][0], i[0][1]]].values\n",
    "        # get convex hull\n",
    "        hull = ConvexHull(points)\n",
    "        # get x and y coordinates\n",
    "        # repeat last point to close the polygon\n",
    "        x_hull = np.append(points[hull.vertices,0],\n",
    "                        points[hull.vertices,0][0])\n",
    "        y_hull = np.append(points[hull.vertices,1],\n",
    "                        points[hull.vertices,1][0])\n",
    "        # plot shape\n",
    "        axs[i[1]].fill(x_hull, y_hull, alpha=0.1, c=colors_clust[j])\n",
    "\n",
    "axs[0,0].set_xscale('log') #bc - k_road_o\n",
    "axs[0,1].set_xscale('log') #bc - k_road_d\n",
    "axs[0,2].set_xscale('log') #bc - voc\n",
    "axs[0,2].set_yscale('log') #bc - voc\n",
    "axs[1,1].set_yscale('log') #k_road_o - voc\n",
    "axs[1,2].set_yscale('log') #k_road_d - voc\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corr_df[['k_road_o', 'k_road_d', 'bc', 'voc']].values\n",
    "y = corr_df['clust_label'].values\n",
    "#scaler = MinMaxScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(2, 10):\n",
    "#    dt = DecisionTreeClassifier(max_depth=i, min_samples_split=50, min_samples_leaf=10)\n",
    "#    print(np.mean(cross_val_score(dt, X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=100)\n",
    "dt = dt.fit(X, y)\n",
    "print(dt.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(dt, out_file=None,\n",
    "                           feature_names=['k_road_o', 'k_road_d', 'bc', 'voc'],\n",
    "                            class_names=['0', '1', '2', '3'],\n",
    "                           filled=True, rounded=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35120d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "print(rf.score(X, y))\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=['k_road_o', 'k_road_d', 'bc', 'voc'])\n",
    "feat_importances.plot(kind='barh')\n",
    "\n",
    "plt.title('Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30f8b884",
   "metadata": {},
   "source": [
    "### 5.2 Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each clustering repeated 20 times, best number of clusters selected with elbow method\n",
    "## Agglomerative params     time    silhouette      calinski\n",
    "## ward                     7m      [3,4]           [4,5]\n",
    "## complete                 7m      [4,5]           [8,9]\n",
    "## average                  6m      [6,7]           [6,7]\n",
    "## single                   2m      [4,5]           [4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c271ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.arange(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_score = {} #silhouette --> 1 better, -1 worse --> elbow method\n",
    "ch_score = {} #calinski_harabasz index --> the higher the better --> elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac49a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)\n",
    "for i in clusters:\n",
    "    sil_tmp = []\n",
    "    ch_tmp = []\n",
    "    for j in range(0, 20):\n",
    "        clf = AgglomerativeClustering(n_clusters=i, linkage='single').fit(X_scaled)\n",
    "        sil_tmp.append(silhouette_score(X_scaled, clf.labels_))\n",
    "        ch_tmp.append(calinski_harabasz_score(X_scaled, clf.labels_))\n",
    "\n",
    "    sil_score[i] = np.array(sil_tmp).mean()\n",
    "    ch_score[i] = np.array(ch_tmp).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sil_score.keys(), sil_score.values(), '-o', ms=3)\n",
    "elbow = KneeLocator(list(sil_score.keys()), list(sil_score.values()), curve='convex', direction='decreasing').knee\n",
    "plt.axvline(elbow, c='tab:red', ls='--')\n",
    "plt.xticks(clusters)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ch_score.keys(), ch_score.values(), '-o', ms=3)\n",
    "elbow = KneeLocator(list(ch_score.keys()), list(ch_score.values()), curve='convex', direction='decreasing').knee\n",
    "plt.axvline(elbow, c='tab:red', ls='--')\n",
    "plt.xticks(clusters)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Calinski-Harabasz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3acf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AgglomerativeClustering(n_clusters=4, linkage='ward').fit(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)\n",
    "print('Silhouette score: ', silhouette_score(X_scaled, clf.labels_))\n",
    "print('Calinski-Harabasz score: ', calinski_harabasz_score(X_scaled, clf.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(clf.labels_))\n",
    "types = ['connector', 'attractor', 'peripheral', 'local']\n",
    "all_comb = []\n",
    "for k in itertools.permutations(labels):\n",
    "    d = {}\n",
    "    for p in zip(k, types):\n",
    "        d[p[0]] = p[1]\n",
    "    all_comb.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin\n",
    "best_comb = {}\n",
    "for c in all_comb:\n",
    "    key = ('-').join([str(i) for sub in c.items() for i in sub])\n",
    "    best_comb[key] = {}\n",
    "    y_clust = pd.Series(clf.labels_).map(c).values\n",
    "    best_comb[key]['accuracy'] = accuracy_score(y_o, y_clust)\n",
    "    best_comb[key]['jaccard'] = jaccard_score(y_o, y_clust, average='weighted')\n",
    "    best_comb[key]['f1'] = f1_score(y_o, y_clust, average='weighted')\n",
    "\n",
    "print('Best accuracy:', max([(k,v['accuracy']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best jaccard:', max([(k,v['jaccard']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best f1:', max([(k,v['f1']) for k,v in best_comb.items()], key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4aebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination\n",
    "best_comb = {}\n",
    "for c in all_comb:\n",
    "    key = ('-').join([str(i) for sub in c.items() for i in sub])\n",
    "    best_comb[key] = {}\n",
    "    y_clust = pd.Series(clf.labels_).map(c).values\n",
    "    best_comb[key]['accuracy'] = accuracy_score(y_d, y_clust)\n",
    "    best_comb[key]['jaccard'] = jaccard_score(y_d, y_clust, average='weighted')\n",
    "    best_comb[key]['f1'] = f1_score(y_d, y_clust, average='weighted')\n",
    "    \n",
    "print('Best accuracy:', max([(k,v['accuracy']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best jaccard:', max([(k,v['jaccard']) for k,v in best_comb.items()], key=lambda x:x[1]))\n",
    "print('Best f1:', max([(k,v['f1']) for k,v in best_comb.items()], key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_clust = {0:'grey', 1:'red', 2:'orange', 3:'green'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2641234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARS: random labeling --> 0, perfect labeling --> 1\n",
    "# FMS: similarity between two clustering, 0 --> no similarity, 1 --> perfect similarity\n",
    "\n",
    "print('Adjusted Rand Score origin: ', adjusted_rand_score(y_o, clf.labels_))\n",
    "print('Fowlked Mallows Score origin: ', fowlkes_mallows_score(y_o, clf.labels_))\n",
    "print('Adjusted Rand Score destination: ', adjusted_rand_score(y_d, clf.labels_))\n",
    "print('Fowlked Mallows Score destination: ', fowlkes_mallows_score(y_d, clf.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a960744",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(10,10))\n",
    "fig.suptitle('Milano_big correlation after clustering', fontweight='bold', y=0.93)\n",
    "\n",
    "c = pd.Series(clf.labels_).map(colors_clust)\n",
    "\n",
    "axs[0,0].scatter(X[:, 0], X[:, 2], s=1, c=c)\n",
    "axs[0,0].set_yscale('log')\n",
    "axs[0,0].set_xlabel('k_road_o')\n",
    "axs[0,0].set_ylabel('bc')\n",
    "\n",
    "axs[0,1].scatter(X[:, 1], X[:, 2], s=1, c=c)\n",
    "axs[0,1].set_yscale('log')\n",
    "axs[0,1].set_xlabel('k_road_d')\n",
    "axs[0,1].set_ylabel('bc')\n",
    "\n",
    "axs[1,0].scatter(X[:, 0], X[:, 3], s=1, c=c)\n",
    "axs[1,0].set_xlabel('k_road_o')\n",
    "axs[1,0].set_ylabel('VOC')\n",
    "\n",
    "axs[1,1].scatter(X[:, 1], X[:, 3], s=1, c=c)\n",
    "axs[1,1].set_xlabel('k_road_d')\n",
    "axs[1,1].set_ylabel('VOC')\n",
    "\n",
    "axs[2,0].scatter(X[:, 2], X[:, 3], s=1, c=c)\n",
    "axs[2,0].set_yscale('log')\n",
    "axs[2,0].set_xscale('log')\n",
    "axs[2,0].set_xlabel('bc')\n",
    "axs[2,0].set_ylabel('VOC')\n",
    "\n",
    "fig.delaxes(axs[2,1])\n",
    "\n",
    "#plt.savefig(path_plots+'k_road_bc_corr.png', bbox_inches =\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362c32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dendrogram(clf, truncate_mode='lastp', p=100, show_contracted=True)\n",
    "plt.ylim(6700, 6900)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6170747e",
   "metadata": {},
   "source": [
    "### 5.3 Plot on map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef12f7d",
   "metadata": {},
   "source": [
    "Plot on map of new clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from shapely.geometry import LineString, Polygon\n",
    "import igraph as ig\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_network = sumolib.net.readNet(road_network_path, withInternal=False)\n",
    "road_edge_map = pd.read_csv(path_road_edge_mapping)\n",
    "\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "for edge in road_network.getEdges():\n",
    "    node_from = edge.getFromNode().getID()\n",
    "    node_to = edge.getToNode().getID()\n",
    "    geom = [list(x) for x in edge.getShape()]\n",
    "    G.add_edge(node_from, node_to, key=edge.getID(), length=edge.getLength(), geometry=LineString(geom))\n",
    "    \n",
    "G.graph.update({'crs': 'epsg:3857'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df_exps, road_edge_map, road_net):\n",
    "    road_edge_map_no_intern = road_edge_map[~road_edge_map['edge_id'].astype(str).str.startswith(':')]\n",
    "    road_edge_mean_map = pd.merge(road_edge_map_no_intern, df_exps, on=['road'])\n",
    "    \n",
    "    # create column with tuple of edges of the graph (u,v,key)\n",
    "    edge_graph_list = []\n",
    "    for edge in road_edge_mean_map['edge_id']:\n",
    "        from_node = road_net.getEdge(edge).getFromNode().getID()\n",
    "        to_node = road_net.getEdge(edge).getToNode().getID()\n",
    "        edge_graph_list.append((from_node, to_node, edge))\n",
    "        \n",
    "    road_edge_mean_map['edge_graph'] = edge_graph_list\n",
    "    \n",
    "    return road_edge_mean_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_plot = plot_df(corr_df, road_edge_map, road_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8049a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c93fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attribute_to_graph(graph, df_plot, attr_name, plot_col):\n",
    "    # edge[0] = node_from, edge[1] = node_to, edge[2] = key = edge_id \n",
    "    \n",
    "    # Initialize co2 attribute in the graph\n",
    "    for edge in graph.edges:\n",
    "        G[edge[0]][edge[1]][edge[2]][attr_name] = None\n",
    "        \n",
    "    # Set co2 attribute based on some value per road\n",
    "    for edge, value in zip(df_plot['edge_graph'], df_plot[plot_col]):\n",
    "        graph[edge[0]][edge[1]][edge[2]][attr_name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a2759",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0:'orange', 1:'grey', 2:'red', 3:'green'}\n",
    "#colors = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red'}\n",
    "corr_plot['color_clust'] = corr_plot['clust_label'].map(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_attribute_to_graph(G, corr_plot, 'color_clust', 'color_clust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11618e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create colormap\n",
    "\n",
    "val = []\n",
    "ind = []\n",
    "for edge in G.edges:\n",
    "    if G[edge[0]][edge[1]][edge[2]]['color_clust'] == None:\n",
    "        val.append('white')\n",
    "        ind.append(edge)\n",
    "    else:\n",
    "        val.append(G[edge[0]][edge[1]][edge[2]]['color_clust'])\n",
    "        ind.append(edge)  \n",
    "\n",
    "ec = pd.Series(val, index=pd.MultiIndex.from_tuples(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ox.plot_graph(G, bgcolor='lightgrey', node_size=0, edge_linewidth=1, edge_color=ec, show=False)\n",
    "\n",
    "plt.title('Milano-big: type of road')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], color='red', lw=4, label='High k_road, high voc'),\n",
    "                   Line2D([0], [0], color='orange', lw=4, label='High k_road, low voc'),\n",
    "                   Line2D([0], [0], color='green', lw=4, label='Low k_road, high voc'),\n",
    "                   Line2D([0], [0], color='grey', lw=4, label='Low k_road, low voc')\n",
    "                   ]\n",
    "\n",
    "ax.legend(handles=legend_elements, bbox_to_anchor=(1.2, 1))\n",
    "plt.savefig(path_plots+'corr_map_clustering.png', bbox_inches =\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92bcf8ac",
   "metadata": {},
   "source": [
    "## 6. CO2 prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0694f",
   "metadata": {},
   "source": [
    "Code for the prediction of the CO2 emissions using the clustering obtained from the K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be378b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for CO2 prediction by different feature sets\n",
    "## Features                 Best model      Train R^2       Test R^2\n",
    "## 4 original features      ElasticNet      0.43            0.57           \n",
    "## No VOC                   ElasticNet      0.27            0.31\n",
    "## Capacity instead of VOC  ElasticNet      0.31            0.24\n",
    "## Extra features           ElasticNet      0.30            0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07983e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add capacity of roads\n",
    "road_network = sumolib.net.readNet(road_network_path, withInternal=False)\n",
    "df_edge_capacity = compute_edge_capacity(road_network.getEdges())\n",
    "df_edge_capacity = pd.DataFrame(df_edge_capacity.items(), columns=['edge_id', 'capacity'])\n",
    "road_edge_map = pd.read_csv(path_road_edge_mapping)\n",
    "df_edge_capacity = pd.merge(df_edge_capacity, road_edge_map, on='edge_id', how='left')\n",
    "weighted_avg = lambda x: np.average(x, weights=df_edge_capacity.loc[x.index, \"edge_len\"])\n",
    "df_edge_capacity = df_edge_capacity.groupby(by=['road']).agg({'capacity': weighted_avg}).reset_index()\n",
    "corr_df = pd.merge(corr_df, df_edge_capacity, on='road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77177c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df2 = corr_df.sample(frac=1)\n",
    "\n",
    "#X = corr_df2[['k_road_o', 'k_road_d', 'bc', 'voc']]\n",
    "#X = corr_df2[['k_road_o', 'k_road_d', 'bc']]\n",
    "#X = corr_df2[['k_road_o', 'k_road_d', 'bc', 'capacity']]\n",
    "X = corr_df2[['k_road_o', 'k_road_d', 'bc', 'capacity', 'road_len', 'intersection', 'speed']]\n",
    "y = corr_df2['co2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{\n",
    "                'model': [LinearRegression()],\n",
    "                'model__fit_intercept': [True],\n",
    "                #'model__positive': [True, False],\n",
    "              },\n",
    "              {\n",
    "                'model': [Ridge()],\n",
    "                #'model__alpha': [0.1, 1, 5, 10, 25, 50, 100],\n",
    "                'model__alpha': np.arange(1,20,0.1),\n",
    "                'model__fit_intercept': [True],\n",
    "                #'model__positive': [True, False],\n",
    "                #'model__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "              },\n",
    "              {\n",
    "                'model': [Lasso()],\n",
    "                #'model__alpha': [0.1, 1, 5, 10, 25, 50, 100],\n",
    "                'model__alpha': np.arange(1,20,0.1),\n",
    "                'model__fit_intercept': [True],\n",
    "                #'model__positive': [True, False],\n",
    "                #'model__selection': ['cyclic', 'random'],\n",
    "                #'model__warm_start': [True, False]\n",
    "              },\n",
    "              {\n",
    "                'model': [ElasticNet()],\n",
    "                #'model__alpha': [0.1, 1, 5, 10, 25, 50, 100],\n",
    "                'model__alpha': np.arange(0.1,3,0.05),\n",
    "                'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                'model__fit_intercept': [True],\n",
    "                #'model__positive': [True, False],\n",
    "                #'model__selection': ['cyclic', 'random'],\n",
    "                #'model__warm_start': [True, False]\n",
    "              }\n",
    "            ]\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', LinearRegression())])\n",
    "clf = GridSearchCV(pipe, param_grid=parameters, cv=5, refit=True, scoring='r2')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ab590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best model: ', clf.best_params_['model'])\n",
    "print('Training score: ', clf.best_score_)\n",
    "model = clf.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "print('Test score: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['k_road_o', 'k_road_d', 'bc', 'voc']\n",
    "#col = ['k_road_o', 'k_road_d', 'bc']\n",
    "#col = ['k_road_o', 'k_road_d', 'bc', 'capacity']\n",
    "#col = ['k_road_o', 'k_road_d', 'bc', 'capacity', 'road_len', 'intersection', 'speed']\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12,7))\n",
    "\n",
    "for i in zip(col, itertools.product(range(2), range(2))):\n",
    "    sns.regplot(x=X_test[i[0]], y=y_pred, scatter_kws={'s':5, 'alpha':0.5}, label='Predicted', ax=axs[i[1]])\n",
    "    sns.regplot(x=X_test[i[0]], y=y_test, scatter_kws={'s':5, 'alpha':0.5}, label='Observed', ax=axs[i[1]])\n",
    "    axs[i[1]].set_yscale('log')\n",
    "    axs[i[1]].legend()\n",
    "\n",
    "axs[1,0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106d5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
